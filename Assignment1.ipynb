{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Photo Booth Application\n",
    "#### This section captures webcam images and saves them to the `images/` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 21:41:12.394 Python[63017:15849358] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2025-02-10 21:41:13.357 Python[63017:15849358] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-10 21:41:13.357 Python[63017:15849358] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved images/image1.jpg\n",
      "Saved images/image2.jpg\n",
      "Saved images/image3.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Function to capture webcam images\n",
    "def capture_webcam():\n",
    "    cap = cv2.VideoCapture(0)  # Open webcam\n",
    "    count = 1  # Image file counter\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('s'):  # Press 's' to save the image\n",
    "            filename = f\"images/image{count}.jpg\"\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"Saved {filename}\")\n",
    "            count += 1\n",
    "        elif key == ord('q'):  # Press 'q' to quit\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the webcam capture function\n",
    "capture_webcam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Image Arithmetic\n",
    "#### This section performs brightness and contrast adjustments, as well as linear blending of two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 21:46:14.399 Python[63017:15849358] _TIPropertyValueIsValid called with 16 on nil context!\n",
      "2025-02-10 21:46:14.399 Python[63017:15849358] imkxpc_getApplicationProperty:reply: called with incorrect property value 16, bailing.\n",
      "2025-02-10 21:46:14.399 Python[63017:15849358] Text input context does not respond to _valueForTIProperty:\n",
      "2025-02-10 21:46:52.220 Python[63017:15849358] _TIPropertyValueIsValid called with 16 on nil context!\n",
      "2025-02-10 21:46:52.220 Python[63017:15849358] imkxpc_getApplicationProperty:reply: called with incorrect property value 16, bailing.\n",
      "2025-02-10 21:46:52.221 Python[63017:15849358] Text input context does not respond to _valueForTIProperty:\n",
      "2025-02-10 21:48:25.139 Python[63017:15849358] _TIPropertyValueIsValid called with 16 on nil context!\n",
      "2025-02-10 21:48:25.139 Python[63017:15849358] imkxpc_getApplicationProperty:reply: called with incorrect property value 16, bailing.\n",
      "2025-02-10 21:48:25.139 Python[63017:15849358] Text input context does not respond to _valueForTIProperty:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m bright_img \u001b[38;5;241m=\u001b[39m make_brighter(img, \u001b[38;5;241m150\u001b[39m)\n\u001b[1;32m     55\u001b[0m contrast_img \u001b[38;5;241m=\u001b[39m change_contrast(img, \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m blended_img \u001b[38;5;241m=\u001b[39m \u001b[43mblend_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages/cat.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages/catdog.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 45\u001b[0m, in \u001b[0;36mblend_images\u001b[0;34m(image1_path, image2_path, alpha)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     44\u001b[0m img2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img2, (img1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], img1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))  \u001b[38;5;66;03m# Resize second image\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mshow_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResized image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m blended \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39maddWeighted(img1, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha, img2, alpha, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Blend images\u001b[39;00m\n\u001b[1;32m     48\u001b[0m show_image(blended, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlended Image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mshow_image\u001b[0;34m(image, title)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow_image\u001b[39m(image, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      6\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(title, image)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      8\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Show the image in a window\n",
    "def show_image(image, title=\"Image\"):\n",
    "    cv2.imshow(title, image)\n",
    "    cv2.waitKey(0) \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Open an image file and display it\n",
    "def open_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(\"Error: Cannot open image!\")\n",
    "        return None\n",
    "    show_image(img, \"Original Image\")\n",
    "    return img\n",
    "\n",
    "# Make image brighter\n",
    "def make_brighter(image, value=150):\n",
    "    image_float = image.astype(np.float32) \n",
    "    bright_img = np.clip(image_float + value, 0, 255) \n",
    "    bright_img = bright_img.astype(np.uint8)\n",
    "    show_image(bright_img, \"Brighter Image\")\n",
    "    return bright_img\n",
    "\n",
    "# Change contrast\n",
    "def change_contrast(image, factor):\n",
    "    image_float = image.astype(np.float32) \n",
    "    contrast_img = np.clip(image_float * factor, 0, 255) \n",
    "    contrast_img = contrast_img.astype(np.uint8) \n",
    "    show_image(contrast_img, \"Contrast Adjusted Image\")\n",
    "    return contrast_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix two images together\n",
    "def blend_images(image1_path, image2_path, alpha):\n",
    "    img1 = cv2.imread(image1_path)\n",
    "    img2 = cv2.imread(image2_path)\n",
    "    \n",
    "    if img1 is None or img2 is None:\n",
    "        print(\"Error: One or both images not found!\")\n",
    "        return None\n",
    "    \n",
    "    img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))  # Resize second image\n",
    "    show_image(img2, \"Resized image\")\n",
    "    \n",
    "    blended = cv2.addWeighted(img1, 1 - alpha, img2, alpha, 0)  # Blend images\n",
    "    show_image(blended, \"Blended Image\")\n",
    "    return blended\n",
    "\n",
    "\n",
    "# test\n",
    "img = open_image(\"images/cat.jpg\")\n",
    "bright_img = make_brighter(img, 150)\n",
    "contrast_img = change_contrast(img, 0.5)\n",
    "\n",
    "# Ask user for alpha value before blending\n",
    "while True:\n",
    "    try:\n",
    "        alpha = float(input(\"Enter a blending factor (alpha) between 0 and 1: \"))\n",
    "        if 0 <= alpha <= 1:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input! Alpha should be between 0 and 1.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input! Please enter a number between 0 and 1.\")\n",
    "\n",
    "# Blend images using user-provided alpha value\n",
    "blended_img = blend_images(\"images/cat.jpg\", \"images/catdog.jpg\", alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: A Drawing Application\n",
    "#### This section enables drawing shapes and adding text to images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Create a program to draw green rectangles on a image with thickness is 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros((500, 500, 3), dtype=np.uint8)\n",
    "\n",
    "color = (0, 255, 0)\n",
    "thickness = 4\n",
    "\n",
    "# Draw multiple small green rectangles\n",
    "cv2.rectangle(image, (100, 100), (150, 150), color, thickness)  \n",
    "cv2.rectangle(image, (200, 100), (250, 150), color, thickness) \n",
    "cv2.rectangle(image, (300, 100), (350, 150), color, thickness)\n",
    "cv2.rectangle(image, (100, 200), (150, 250), color, thickness)  \n",
    "cv2.rectangle(image, (200, 200), (250, 250), color, thickness) \n",
    "cv2.rectangle(image, (300, 200), (350, 250), color, thickness) \n",
    "cv2.rectangle(image, (100, 300), (150, 350), color, thickness) \n",
    "cv2.rectangle(image, (200, 300), (250, 350), color, thickness)  \n",
    "cv2.rectangle(image, (300, 300), (350, 350), color, thickness) \n",
    "\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Change thickness to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness = -1\n",
    "\n",
    "# Draw multiple small green rectangles\n",
    "cv2.rectangle(image, (100, 100), (150, 150), color, thickness)  \n",
    "cv2.rectangle(image, (200, 100), (250, 150), color, thickness) \n",
    "cv2.rectangle(image, (300, 100), (350, 150), color, thickness)\n",
    "cv2.rectangle(image, (100, 200), (150, 250), color, thickness)  \n",
    "cv2.rectangle(image, (200, 200), (250, 250), color, thickness) \n",
    "cv2.rectangle(image, (300, 200), (350, 250), color, thickness) \n",
    "cv2.rectangle(image, (100, 300), (150, 350), color, thickness) \n",
    "cv2.rectangle(image, (200, 300), (250, 350), color, thickness)  \n",
    "cv2.rectangle(image, (300, 300), (350, 350), color, thickness) \n",
    "\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Create a program to put Text On the Rectangle in the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros((500, 500, 3), dtype=np.uint8)\n",
    "\n",
    "thickness = -1\n",
    "\n",
    "cv2.rectangle(image, (100, 100), (400, 400), color, thickness)\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "text = \"CVI Assignment\"\n",
    "text_position = (100, 250) \n",
    "font_scale = 1.2\n",
    "font_color = (200, 255, 255) \n",
    "thickness = 2\n",
    "cv2.putText(image, text, text_position, font, font_scale, font_color, thickness)\n",
    "\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision_win_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
